{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exective summary of Work Package 3\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this WP, you will work on a given training dataset. Your goal is to develop a fault detection model using the regression algorithms learnt in the class, in order to achieve best F1 scoreã€‚\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Task 1: Develop a regression model to predict the reference value for motor temperature.\n",
    "- Task 2: Develop a fault detection model using the regression model you developed in Task 1.\n",
    "\n",
    "## Delierables\n",
    "\n",
    "- A Jupyter notebook reporting the process and results of the above tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting, please:\n",
    "- Fetch the most up-to-date version of the github repository.\n",
    "- Create a new branch with your name, based on the \"main\" branch and switch to your own branch.\n",
    "- Copy this notebook to the work space of your group, and rename it to TD_WP_3_Your name.ipynb\n",
    "- After finishing this task, push your changes to the github repository of your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Predict normal behaviors through regression models\n",
    "\n",
    "In this task, let us try to develop a best regression model to predict the normal behaviors of a given motor. In this exercise, we can use motor 6 as an example. You can easilily generate the approach to other models for the data challenge.\n",
    "\n",
    "We can use all the dataset where motor 6 works normally as our dataset. Then, we can run a cross validation (based on sequence, not points) to test the performances of the developed model.\n",
    "\n",
    "In this example, we mainly use the following performance metrics:\n",
    "- max error: The max error between the predicted and the true values.\n",
    "- Mean root squared error: The mean root squared error between the predicted and the true values.\n",
    "- Out-of-boundary rate: The percentage that the residual error between the predicted and the true values is larger than a given threshold. Here, we set the thresold to be $3$ degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-task 1: Only use the features at the current moment.\n",
    "\n",
    "[This notebook](demo_regression_mdl.ipynb) provides a basic demonstration of how to set up the experiment. Let us start by considering only using the features from the current moment. In the notebook, we show a baseline using a simple linear regression with all the features. Could you please try to improve the performance of the model?\n",
    "\n",
    "A few possible directions:\n",
    "- Feature selection?\n",
    "- Smoothing?\n",
    "- Removing sequence-to-sequence variablity? Adding features regarding time dynamics (see the TD for last lecture).\n",
    "- Changing to other regression models? For this, you can try different regression models from [here](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "Put your code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Visulize the data\\nfor selected_sequence_idx in path_list:\\n    filtered_df = df_data_smoothing[df_data_smoothing['test_condition'] == selected_sequence_idx]\\n\\n    print('{}: {}\\n'.format(selected_sequence_idx, df_test_conditions[df_test_conditions['Test id'] == selected_sequence_idx]['Description']))\\n\\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\\n    for ax, col in zip(axes.flat, ['data_motor_1_position', 'data_motor_2_position', 'data_motor_3_position', \\n        'data_motor_1_temperature', 'data_motor_2_temperature', 'data_motor_3_temperature',\\n        'data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage']):\\n        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\\n        ax.set_ylabel(col)\\n\\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\\n    for ax, col in zip(axes.flat, ['data_motor_4_position', 'data_motor_5_position', 'data_motor_6_position',\\n        'data_motor_4_temperature', 'data_motor_5_temperature', 'data_motor_6_temperature',\\n        'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage']):\\n        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\\n        ax.set_ylabel(col)\\n\\n    plt.show()\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utility2 import read_all_test_data_from_path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Remove outliers from the dataframe based on defined valid ranges. \n",
    "    Define a valid range of temperature and voltage. \n",
    "    Use ffil function to replace the invalid measurement with the previous value.\n",
    "    '''\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "    df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] <= 9000, np.nan)\n",
    "    df['voltage'] = df['voltage'].ffill()\n",
    "\n",
    "    df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "    df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "    df['position'] = df['position'].ffill()\n",
    "\n",
    "\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "df_data = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)\n",
    "\n",
    "df_data.describe()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n",
    "# Function to design a Butterworth low-pass filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "# Function to apply the Butterworth low-pass filter\n",
    "def lowpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
    "    b, a = butter_lowpass(cutoff_freq, sampling_freq, order=order)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "# Set parameters for the low-pass filter\n",
    "cutoff_frequency = 0.05  # Adjust as needed\n",
    "sampling_frequency = 10  # Assuming your data is evenly spaced in time\n",
    "\n",
    "\n",
    "def customized_outlier_removal(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Remove outliers from the dataframe based on defined valid ranges. \n",
    "    Define a valid range of temperature and voltage. \n",
    "    Use ffil function to replace the invalid measurement with the previous value.\n",
    "    '''\n",
    "    df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "    df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "    df['position'] = df['position'].ffill()\n",
    "    df['position'] = lowpass_filter(df['position'], cutoff_frequency, sampling_frequency)\n",
    "    df['position'] = df['position'].rolling(window=20, min_periods=1).mean()\n",
    "    df['position'] = df['position'].round()\n",
    "\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "    df['temperature'] = df['temperature'].rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "    # Make sure that the difference between the current and previous temperature cannot be too large.\n",
    "    # Define your threshold\n",
    "    threshold = 4\n",
    "    # Shift the 'temperature' column by one row to get the previous temperature\n",
    "    prev_tmp = df['temperature'].shift(1)\n",
    "    # Calculate the absolute difference between current and previous temperature\n",
    "    temp_diff = np.abs(df['temperature'] - prev_tmp)\n",
    "    # Set the temperature to NaN where the difference is larger than the threshold\n",
    "    df.loc[temp_diff > threshold, 'temperature'] = np.nan\n",
    "    df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] <= 8000, np.nan)\n",
    "    df['voltage'] = df['voltage'].ffill()\n",
    "    df['voltage'] = lowpass_filter(df['voltage'], cutoff_frequency, sampling_frequency)\n",
    "    df['voltage'] = df['voltage'].rolling(window=20, min_periods=1).mean()\n",
    "    \n",
    "\n",
    "from utility2 import read_all_csvs_one_test\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get all the folders in the base_dictionary\n",
    "path_list = os.listdir(base_dictionary)\n",
    "# Only keep the folders, not the excel file.\n",
    "path_list = path_list[:-1]\n",
    "\n",
    "# Read the data.\n",
    "df_data_smoothing = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df = read_all_csvs_one_test(path, tmp_path, customized_outlier_removal)\n",
    "    df_data_smoothing = pd.concat([df_data_smoothing, tmp_df])\n",
    "    df_data_smoothing = df_data_smoothing.reset_index(drop=True)\n",
    "\n",
    "# Read the test conditions\n",
    "df_test_conditions = pd.read_excel(base_dictionary+'Test conditions.xlsx')\n",
    "\n",
    "'''# Visulize the data\n",
    "for selected_sequence_idx in path_list:\n",
    "    filtered_df = df_data_smoothing[df_data_smoothing['test_condition'] == selected_sequence_idx]\n",
    "\n",
    "    print('{}: {}\\n'.format(selected_sequence_idx, df_test_conditions[df_test_conditions['Test id'] == selected_sequence_idx]['Description']))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "    for ax, col in zip(axes.flat, ['data_motor_1_position', 'data_motor_2_position', 'data_motor_3_position', \n",
    "        'data_motor_1_temperature', 'data_motor_2_temperature', 'data_motor_3_temperature',\n",
    "        'data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage']):\n",
    "        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "    for ax, col in zip(axes.flat, ['data_motor_4_position', 'data_motor_5_position', 'data_motor_6_position',\n",
    "        'data_motor_4_temperature', 'data_motor_5_temperature', 'data_motor_6_temperature',\n",
    "        'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage']):\n",
    "        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select only the normal samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_id = ['20240105_164214', \n",
    "    '20240105_165300', \n",
    "    '20240105_165972', \n",
    "    '20240320_152031', \n",
    "    '20240320_153841', \n",
    "    '20240320_155664', \n",
    "    '20240321_122650', \n",
    "    '20240325_135213', \n",
    "    '20240426_141190', \n",
    "    '20240426_141532', \n",
    "    '20240426_141602', \n",
    "    '20240426_141726', \n",
    "    '20240426_141938', \n",
    "    '20240426_141980', \n",
    "    '20240503_164435']\n",
    "df_data = df_data[df_data['test_condition'].isin(normal_test_id)]\n",
    "df_data_smoothing = df_data_smoothing[df_data_smoothing['test_condition'].isin(normal_test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define the steps of the pipeline\n",
    "# Ignore warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Steps for Ridge Regression\n",
    "svr_steps = [\n",
    "    ('Normailzer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    ('regressor', SVR())               # Step 2: Ridge Regression\n",
    "]\n",
    "\n",
    "# Steps for Lasso Regression\n",
    "polynom_steps = [\n",
    "    ('Normailzer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    ('regressor', PolynomialFeatures())               # Step 2: Lasso Regression\n",
    "]\n",
    "\n",
    "# Steps for Linear Regression\n",
    "linear_regression_steps = [\n",
    "    ('Normailzer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    ('regressor', LinearRegression())    # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Steps for ElasticNet Regression\n",
    "elasticnet_regression_steps = [\n",
    "    ('Normailzer', StandardScaler()),  # Step 1: Normalization\n",
    "    ('regressor', ElasticNet())          # Step 2: ElasticNet Regression\n",
    "]\n",
    "\n",
    "# Steps for Decision Tree Regression\n",
    "decision_tree_steps = [\n",
    "    ('Normailzerr', StandardScaler()),  # Step 1: Normalization\n",
    "    ('regressor', DecisionTreeRegressor())  # Step 2: Decision Tree Regressor\n",
    "]\n",
    "\n",
    "# Initialize Pipelines for each model\n",
    "mdl_linear_regression = Pipeline(linear_regression_steps)\n",
    "mdl_svr_regression = Pipeline(svr_steps)\n",
    "mdl_polynom_regression = Pipeline(polynom_steps)\n",
    "mdl_elasticnet_regression = Pipeline(elasticnet_regression_steps)\n",
    "mdl_decision_tree = Pipeline(decision_tree_steps)\n",
    "\n",
    "# List of models to be used in GridSearchCV\n",
    "models = [\n",
    "    ('SVR', mdl_svr_regression),\n",
    "    ('Linear Regression', mdl_linear_regression),\n",
    "    ('polynom', mdl_polynom_regression),\n",
    "    ('ElasticNet Regression', mdl_elasticnet_regression),\n",
    "    ('Decision Tree Regression', mdl_decision_tree),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: SVR\n",
      "Model for predicting temperature of motor 1:\n",
      "Model for motor 1:\n"
     ]
    }
   ],
   "source": [
    "from utility2 import run_cv_one_motor\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "threshold = 1\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "\n",
    "def run_all_motors(df_data, mdl, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "            prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    all_results = []\n",
    "    # Loop over all the six motors.\n",
    "    for i in range(1, 7):\n",
    "        print(f'Model for predicting temperature of motor {i}:')\n",
    "        # Run cross validation.\n",
    "        df_perf = run_cv_one_motor(motor_idx=i, df_data=df_data, mdl=mdl, feature_list=feature_list,\n",
    "                n_fold=n_fold, threshold=threshold, window_size=window_size, sample_step=sample_step,\n",
    "            prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, mdl_type=mdl_type)\n",
    "        all_results.append(df_perf)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def run_all_models(df_data, models, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "                   prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    summary_results = []\n",
    "    for name, mdl in models:\n",
    "        print(f'Running model: {name}')\n",
    "        all_results = run_all_motors(df_data, mdl, feature_list, n_fold=n_fold, threshold=threshold, \n",
    "                                     window_size=window_size, sample_step=sample_step,\n",
    "                                     prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, \n",
    "                                     mdl_type=mdl_type)\n",
    "        \n",
    "        # Agregar resultados para cada motor\n",
    "        df_all_results = pd.concat(all_results, keys=[f'Motor_{i}' for i in range(1, 7)])\n",
    "        summary_results.append((name, df_all_results))\n",
    "    \n",
    "    return summary_results\n",
    "\n",
    "all_model_results = run_all_models(df_data=df_data, models=models, feature_list=feature_list_all, \n",
    "                                   threshold=threshold, window_size=window_size, sample_step=sample_step, \n",
    "                                   single_run_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for motor 6:\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    }
   ],
   "source": [
    "from utility2 import run_cv_one_motor\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "threshold = 1\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "\n",
    "df_perf = run_cv_one_motor(single_run_result=False, motor_idx=6, df_data=df_data_smoothing, mdl=grid_search, \n",
    "            feature_list=feature_list_all, n_fold=5, \n",
    "            threshold=threshold, window_size=window_size, sample_step=sample_step, mdl_type='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the results - Only using features from the current moment**\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models. Please write a few texts to explain what is the best model you got (including the features and preprocessing you did), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Max error | MRSE | Exceed boundary rate |\n",
    "|---------|----------|-----------|--------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-task 2: Include the features in the past\n",
    "\n",
    "Now, let's consider using the sliding window approach to include the past in the regression model as well. Please have a look at the demo notebook, run your experiment, and report the best models you could have if you apply the sliding window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the results - Sliding window**\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models. Please write a few texts to explain what is the best model you got (including the features and preprocessing you did), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   (also report parameters like window_size, sample_step, prediction_lead_time, etc.) | Max error | MRSE | Exceed boundary rate |\n",
    "|---------|----------|-----------|--------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Fault detection based on regression model\n",
    "\n",
    "In this exercise, we use the dataset that contains the failure of motor 6 to test the fault detection model based on the regression model trained before. \n",
    "\n",
    "[This notebook](demo_FaultDetectReg.ipynb) presents a demonstration of how to use the provided supporting function to develop fault detection model based on the regression model. Please have a look at this notebook, and try to improve the performance of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the results\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models (including the unsupervised learning models). Please write a few texts to explain what is the best model you got (including key parameters like threshold, window_size, sample_step, prediction_lead_time, etc), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Accuracy | Precision | Recall | F1   |\n",
    "|---------|----------|-----------|--------|------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
