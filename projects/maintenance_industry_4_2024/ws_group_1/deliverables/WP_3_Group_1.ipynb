{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exective summary of Work Package 3\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this WP, you will work on a given training dataset. Your goal is to develop a fault detection model using the regression algorithms learnt in the class, in order to achieve best F1 scoreã€‚\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Task 1: Develop a regression model to predict the reference value for motor temperature.\n",
    "- Task 2: Develop a fault detection model using the regression model you developed in Task 1.\n",
    "\n",
    "## Delierables\n",
    "\n",
    "- A Jupyter notebook reporting the process and results of the above tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting, please:\n",
    "- Fetch the most up-to-date version of the github repository.\n",
    "- Create a new branch with your name, based on the \"main\" branch and switch to your own branch.\n",
    "- Copy this notebook to the work space of your group, and rename it to TD_WP_3_Your name.ipynb\n",
    "- After finishing this task, push your changes to the github repository of your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Predict normal behaviors through regression models\n",
    "\n",
    "In this task, let us try to develop a best regression model to predict the normal behaviors of a given motor. In this exercise, we can use motor 6 as an example. You can easilily generate the approach to other models for the data challenge.\n",
    "\n",
    "We can use all the dataset where motor 6 works normally as our dataset. Then, we can run a cross validation (based on sequence, not points) to test the performances of the developed model.\n",
    "\n",
    "In this example, we mainly use the following performance metrics:\n",
    "- max error: The max error between the predicted and the true values.\n",
    "- Mean root squared error: The mean root squared error between the predicted and the true values.\n",
    "- Out-of-boundary rate: The percentage that the residual error between the predicted and the true values is larger than a given threshold. Here, we set the thresold to be $3$ degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-task 1: Only use the features at the current moment.\n",
    "\n",
    "[This notebook](demo_regression_mdl.ipynb) provides a basic demonstration of how to set up the experiment. Let us start by considering only using the features from the current moment. In the notebook, we show a baseline using a simple linear regression with all the features. Could you please try to improve the performance of the model?\n",
    "\n",
    "A few possible directions:\n",
    "- Feature selection?\n",
    "- Smoothing?\n",
    "- Removing sequence-to-sequence variablity? Adding features regarding time dynamics (see the TD for last lecture).\n",
    "- Changing to other regression models? For this, you can try different regression models from [here](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "Put your code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Read the test conditions\\ndf_test_conditions = pd.read_excel(base_dictionary+'Test conditions.xlsx')\\n\\n# Visulize the data\\nfor selected_sequence_idx in path_list:\\n    filtered_df = df_data_smoothing[df_data_smoothing['test_condition'] == selected_sequence_idx]\\n\\n    print('{}: {}\\n'.format(selected_sequence_idx, df_test_conditions[df_test_conditions['Test id'] == selected_sequence_idx]['Description']))\\n\\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\\n    for ax, col in zip(axes.flat, ['data_motor_1_position', 'data_motor_2_position', 'data_motor_3_position', \\n        'data_motor_1_temperature', 'data_motor_2_temperature', 'data_motor_3_temperature',\\n        'data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage']):\\n        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\\n        ax.set_ylabel(col)\\n\\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\\n    for ax, col in zip(axes.flat, ['data_motor_4_position', 'data_motor_5_position', 'data_motor_6_position',\\n        'data_motor_4_temperature', 'data_motor_5_temperature', 'data_motor_6_temperature',\\n        'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage']):\\n        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\\n        ax.set_ylabel(col)\\n\\n    plt.show()\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utility import read_all_test_data_from_path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "n_int = 20\n",
    "\n",
    "# Subfunction for data preprocessing.\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    '''\n",
    "    \n",
    "    # Function to design a Butterworth low-pass filter\n",
    "    def butter_lowpass(cutoff, fs, order=5):\n",
    "        nyquist = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "\n",
    "    # Function to apply the Butterworth low-pass filter\n",
    "    def lowpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
    "        b, a = butter_lowpass(cutoff_freq, sampling_freq, order=order)\n",
    "        filtered_data = filtfilt(b, a, data)\n",
    "        return filtered_data\n",
    "\n",
    "\n",
    "    # Set parameters for the low-pass filter\n",
    "    cutoff_frequency = .05  # Adjust as needed\n",
    "    sampling_frequency = 10  # Assuming your data is evenly spaced in time\n",
    "\n",
    "\n",
    "    def customized_outlier_removal(df: pd.DataFrame):\n",
    "        ''' # Description\n",
    "        Remove outliers from the dataframe based on defined valid ranges. \n",
    "        Define a valid range of temperature and voltage. \n",
    "        Use ffil function to replace the invalid measurement with the previous value.\n",
    "        '''\n",
    "        df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "        df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "        df['position'] = df['position'].ffill()\n",
    "        df['position'] = lowpass_filter(df['position'], cutoff_frequency, sampling_frequency)\n",
    "        df['position'] = df['position'].rolling(window=20, min_periods=1).mean()\n",
    "        df['position'] = df['position'].round()\n",
    "\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "        df['temperature'] = df['temperature'].rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "        # Make sure that the difference between the current and previous temperature cannot be too large.\n",
    "        # Define your threshold\n",
    "        threshold = 5\n",
    "        # Shift the 'temperature' column by one row to get the previous temperature\n",
    "        prev_tmp = df['temperature'].shift(1)\n",
    "        # Calculate the absolute difference between current and previous temperature\n",
    "        temp_diff = np.abs(df['temperature'] - prev_tmp)\n",
    "        # Set the temperature to NaN where the difference is larger than the threshold\n",
    "        df.loc[temp_diff > threshold, 'temperature'] = np.nan\n",
    "        df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] <= 8000, np.nan)\n",
    "        df['voltage'] = df['voltage'].ffill()\n",
    "        df['voltage'] = lowpass_filter(df['voltage'], cutoff_frequency, sampling_frequency)\n",
    "        df['voltage'] = df['voltage'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "\n",
    "    def cal_diff(df: pd.DataFrame, n_int: int):\n",
    "        ''' # Description\n",
    "        Calculate the difference between the current and previous n data point.\n",
    "        '''\n",
    "        # Tranform the features relative to the first data point.\n",
    "        df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "        df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "        df['position'] = df['position'] - df['position'].iloc[0]\n",
    "\n",
    "        # Calculate the difference between the current and previous n data point.\n",
    "        df['temperature_diff'] = df['temperature'].diff(n_int)\n",
    "        df['voltage_diff'] = df['voltage'].diff(n_int)\n",
    "        df['position_diff'] = df['position'].diff(n_int)   \n",
    "\n",
    "    # Start processing.\n",
    "    customized_outlier_removal(df)\n",
    "    cal_diff(df, n_int)\n",
    "\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "df_data = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)\n",
    "    \n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get all the folders in the base_dictionary\n",
    "path_list = os.listdir(base_dictionary)\n",
    "# Only keep the folders, not the excel file.\n",
    "path_list = path_list[:-1]\n",
    "\n",
    "# Read the data.\n",
    "df_data_smoothing = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df = read_all_csvs_one_test(path, tmp_path, customized_outlier_removal)\n",
    "    df_data_smoothing = pd.concat([df_data_smoothing, tmp_df])\n",
    "    df_data_smoothing = df_data_smoothing.reset_index(drop=True)\n",
    "\n",
    "'''# Read the test conditions\n",
    "df_test_conditions = pd.read_excel(base_dictionary+'Test conditions.xlsx')\n",
    "\n",
    "# Visulize the data\n",
    "for selected_sequence_idx in path_list:\n",
    "    filtered_df = df_data_smoothing[df_data_smoothing['test_condition'] == selected_sequence_idx]\n",
    "\n",
    "    print('{}: {}\\n'.format(selected_sequence_idx, df_test_conditions[df_test_conditions['Test id'] == selected_sequence_idx]['Description']))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "    for ax, col in zip(axes.flat, ['data_motor_1_position', 'data_motor_2_position', 'data_motor_3_position', \n",
    "        'data_motor_1_temperature', 'data_motor_2_temperature', 'data_motor_3_temperature',\n",
    "        'data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage']):\n",
    "        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "    for ax, col in zip(axes.flat, ['data_motor_4_position', 'data_motor_5_position', 'data_motor_6_position',\n",
    "        'data_motor_4_temperature', 'data_motor_5_temperature', 'data_motor_6_temperature',\n",
    "        'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage']):\n",
    "        ax.plot(filtered_df['time'], filtered_df[col], marker='o', label=col)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select only the normal samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_id = ['20240105_164214', \n",
    "    '20240105_165300', \n",
    "    '20240105_165972', \n",
    "    '20240320_152031', \n",
    "    '20240320_153841', \n",
    "    '20240320_155664', \n",
    "    '20240321_122650', \n",
    "    '20240325_135213', \n",
    "    '20240426_141190', \n",
    "    '20240426_141532', \n",
    "    '20240426_141602', \n",
    "    '20240426_141726', \n",
    "    '20240426_141938', \n",
    "    '20240426_141980', \n",
    "    '20240503_164435']\n",
    "df_data = df_data[df_data['test_condition'].isin(normal_test_id)]\n",
    "df_data_smoothing = df_data_smoothing[df_data_smoothing['test_condition'].isin(normal_test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define the steps of the pipeline\n",
    "# Ignore warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Steps for Ridge Regression\n",
    "svr_steps = [\n",
    "    ('Normailzer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    ('regressor', SVR())               # Step 2: Ridge Regression\n",
    "]\n",
    "\n",
    "# Steps for Lasso Regression\n",
    "polynom_steps = [\n",
    "    ('Normailzer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    ('regressor', PolynomialFeatures())               # Step 2: Lasso Regression\n",
    "]\n",
    "\n",
    "# Steps for Linear Regression\n",
    "linear_regression_steps = [\n",
    "    ('Normailzer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    ('regressor', LinearRegression())    # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Steps for ElasticNet Regression\n",
    "elasticnet_regression_steps = [\n",
    "    ('Normailzer', StandardScaler()),  # Step 1: Normalization\n",
    "    ('regressor', ElasticNet())          # Step 2: ElasticNet Regression\n",
    "]\n",
    "\n",
    "# Steps for Decision Tree Regression\n",
    "decision_tree_steps = [\n",
    "    ('Normailzerr', StandardScaler()),  # Step 1: Normalization\n",
    "    ('regressor', DecisionTreeRegressor())  # Step 2: Decision Tree Regressor\n",
    "]\n",
    "\n",
    "# Initialize Pipelines for each model\n",
    "mdl_linear_regression = Pipeline(linear_regression_steps)\n",
    "mdl_svr_regression = Pipeline(svr_steps)\n",
    "mdl_polynom_regression = Pipeline(polynom_steps)\n",
    "mdl_elasticnet_regression = Pipeline(elasticnet_regression_steps)\n",
    "mdl_decision_tree = Pipeline(decision_tree_steps)\n",
    "\n",
    "# List of models to be used in GridSearchCV\n",
    "models = [\n",
    "    ('SVR', mdl_svr_regression),\n",
    "    ('Linear Regression', mdl_linear_regression),\n",
    "    ('polynom', mdl_polynom_regression),\n",
    "    ('ElasticNet Regression', mdl_elasticnet_regression),\n",
    "    ('Decision Tree Regression', mdl_decision_tree),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import run_cv_one_motor\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "threshold = 1\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "\n",
    "def run_all_motors(df_data, mdl, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "            prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    all_results = []\n",
    "    # Loop over all the six motors.\n",
    "    for i in range(1, 7):\n",
    "        print(f'Model for predicting temperature of motor {i}:')\n",
    "        # Run cross validation.\n",
    "        df_perf = run_cv_one_motor(motor_idx=i, df_data=df_data, mdl=mdl, feature_list=feature_list,\n",
    "                n_fold=n_fold, threshold=threshold, window_size=window_size, sample_step=sample_step,\n",
    "            prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, mdl_type=mdl_type)\n",
    "        all_results.append(df_perf)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def run_all_models(df_data, models, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "                   prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    summary_results = []\n",
    "    for name, mdl in models:\n",
    "        print(f'Running model: {name}')\n",
    "        all_results = run_all_motors(df_data, mdl, feature_list, n_fold=n_fold, threshold=threshold, \n",
    "                                     window_size=window_size, sample_step=sample_step,\n",
    "                                     prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, \n",
    "                                     mdl_type=mdl_type)\n",
    "        \n",
    "        # Agregar resultados para cada motor\n",
    "        df_all_results = pd.concat(all_results, keys=[f'Motor_{i}' for i in range(1, 7)])\n",
    "        summary_results.append((name, df_all_results))\n",
    "    \n",
    "    return summary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for motor 6:\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    }
   ],
   "source": [
    "from utility import run_cv_one_motor\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "threshold = 1\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "\n",
    "df_perf = run_cv_one_motor(single_run_result=False, motor_idx=6, df_data=df_data_smoothing, mdl=grid_search, \n",
    "            feature_list=feature_list_all, n_fold=5, \n",
    "            threshold=threshold, window_size=window_size, sample_step=sample_step, mdl_type='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: SVR\n",
      "Model for predicting temperature of motor 1:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['data_motor_1_temperature_diff', 'data_motor_1_voltage_diff', 'data_motor_1_position_diff', 'data_motor_2_temperature_diff', 'data_motor_2_voltage_diff', 'data_motor_2_position_diff', 'data_motor_3_temperature_diff', 'data_motor_3_voltage_diff', 'data_motor_3_position_diff', 'data_motor_4_temperature_diff', 'data_motor_4_voltage_diff', 'data_motor_4_position_diff', 'data_motor_5_temperature_diff', 'data_motor_5_voltage_diff', 'data_motor_5_position_diff', 'data_motor_6_temperature_diff', 'data_motor_6_voltage_diff', 'data_motor_6_position_diff'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m sample_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 34\u001b[0m all_model_results \u001b[38;5;241m=\u001b[39m run_all_models(df_data\u001b[38;5;241m=\u001b[39mdf_data_smoothing, models\u001b[38;5;241m=\u001b[39mmodels, feature_list\u001b[38;5;241m=\u001b[39mfeature_list_all, \n\u001b[0;32m     35\u001b[0m                                    threshold\u001b[38;5;241m=\u001b[39mthreshold, window_size\u001b[38;5;241m=\u001b[39mwindow_size, sample_step\u001b[38;5;241m=\u001b[39msample_step, \n\u001b[0;32m     36\u001b[0m                                    single_run_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m all_model_results \u001b[38;5;241m=\u001b[39m run_all_models(df_data\u001b[38;5;241m=\u001b[39mdf_data_smoothing, models\u001b[38;5;241m=\u001b[39mmodels, feature_list\u001b[38;5;241m=\u001b[39mselected_features, \n\u001b[0;32m     39\u001b[0m                                    threshold\u001b[38;5;241m=\u001b[39mthreshold, window_size\u001b[38;5;241m=\u001b[39mwindow_size, sample_step\u001b[38;5;241m=\u001b[39msample_step, \n\u001b[0;32m     40\u001b[0m                                    single_run_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m, in \u001b[0;36mrun_all_models\u001b[1;34m(df_data, models, feature_list, n_fold, threshold, window_size, sample_step, prediction_lead_time, single_run_result, mdl_type)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mdl \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m run_all_motors(df_data, mdl, feature_list, n_fold\u001b[38;5;241m=\u001b[39mn_fold, threshold\u001b[38;5;241m=\u001b[39mthreshold, \n\u001b[0;32m     34\u001b[0m                                  window_size\u001b[38;5;241m=\u001b[39mwindow_size, sample_step\u001b[38;5;241m=\u001b[39msample_step,\n\u001b[0;32m     35\u001b[0m                                  prediction_lead_time\u001b[38;5;241m=\u001b[39mprediction_lead_time, single_run_result\u001b[38;5;241m=\u001b[39msingle_run_result, \n\u001b[0;32m     36\u001b[0m                                  mdl_type\u001b[38;5;241m=\u001b[39mmdl_type)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Agregar resultados para cada motor\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     df_all_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_results, keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMotor_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m)])\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mrun_all_motors\u001b[1;34m(df_data, mdl, feature_list, n_fold, threshold, window_size, sample_step, prediction_lead_time, single_run_result, mdl_type)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel for predicting temperature of motor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Run cross validation.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     df_perf \u001b[38;5;241m=\u001b[39m run_cv_one_motor(motor_idx\u001b[38;5;241m=\u001b[39mi, df_data\u001b[38;5;241m=\u001b[39mdf_data, mdl\u001b[38;5;241m=\u001b[39mmdl, feature_list\u001b[38;5;241m=\u001b[39mfeature_list,\n\u001b[0;32m     22\u001b[0m             n_fold\u001b[38;5;241m=\u001b[39mn_fold, threshold\u001b[38;5;241m=\u001b[39mthreshold, window_size\u001b[38;5;241m=\u001b[39mwindow_size, sample_step\u001b[38;5;241m=\u001b[39msample_step,\n\u001b[0;32m     23\u001b[0m         prediction_lead_time\u001b[38;5;241m=\u001b[39mprediction_lead_time, single_run_result\u001b[38;5;241m=\u001b[39msingle_run_result, mdl_type\u001b[38;5;241m=\u001b[39mmdl_type)\n\u001b[0;32m     24\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(df_perf)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "File \u001b[1;32mc:\\Users\\marce\\OneDrive\\Documents\\CS\\SG8_industry_4.0\\digital_twin_robot\\projects\\maintenance_industry_4_2024\\ws_group_1\\deliverables\\utility.py:373\u001b[0m, in \u001b[0;36mrun_cv_one_motor\u001b[1;34m(motor_idx, df_data, mdl, feature_list, n_fold, threshold, window_size, sample_step, prediction_lead_time, single_run_result, mdl_type)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' ### Description\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03mRun cross validation for a given motor and return the performance metrics for each cv run.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03mCan be used for both classification and regression models.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# Extract the selected features.\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m df_x, y \u001b[38;5;241m=\u001b[39m extract_selected_feature(df_data, feature_list, motor_idx, mdl_type)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel for motor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmotor_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# Run cross validation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marce\\OneDrive\\Documents\\CS\\SG8_industry_4.0\\digital_twin_robot\\projects\\maintenance_industry_4_2024\\ws_group_1\\deliverables\\utility.py:340\u001b[0m, in \u001b[0;36mextract_selected_feature\u001b[1;34m(df_data, feature_list, motor_idx, mdl_type)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Seperate features and the response variable.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Remove the irrelavent features.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m feature_list_local\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_condition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 340\u001b[0m df_x \u001b[38;5;241m=\u001b[39m df_data[feature_list_local]\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Get y.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m y \u001b[38;5;241m=\u001b[39m df_data\u001b[38;5;241m.\u001b[39mloc[:, y_name]\n",
      "File \u001b[1;32mc:\\Users\\marce\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\marce\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marce\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['data_motor_1_temperature_diff', 'data_motor_1_voltage_diff', 'data_motor_1_position_diff', 'data_motor_2_temperature_diff', 'data_motor_2_voltage_diff', 'data_motor_2_position_diff', 'data_motor_3_temperature_diff', 'data_motor_3_voltage_diff', 'data_motor_3_position_diff', 'data_motor_4_temperature_diff', 'data_motor_4_voltage_diff', 'data_motor_4_position_diff', 'data_motor_5_temperature_diff', 'data_motor_5_voltage_diff', 'data_motor_5_position_diff', 'data_motor_6_temperature_diff', 'data_motor_6_voltage_diff', 'data_motor_6_position_diff'] not in index\""
     ]
    }
   ],
   "source": [
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature','data_motor_1_voltage',\n",
    "       'data_motor_1_temperature_diff', 'data_motor_1_voltage_diff','data_motor_1_position_diff', \n",
    "       'data_motor_2_position','data_motor_2_temperature', 'data_motor_2_voltage', \n",
    "       'data_motor_2_temperature_diff', 'data_motor_2_voltage_diff', 'data_motor_2_position_diff',\n",
    "       'data_motor_3_position', 'data_motor_3_temperature','data_motor_3_voltage',\n",
    "       'data_motor_3_temperature_diff', 'data_motor_3_voltage_diff','data_motor_3_position_diff', \n",
    "       'data_motor_4_position','data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "       'data_motor_4_temperature_diff', 'data_motor_4_voltage_diff', 'data_motor_4_position_diff',\n",
    "       'data_motor_5_position', 'data_motor_5_temperature','data_motor_5_voltage',\n",
    "       'data_motor_5_temperature_diff', 'data_motor_5_voltage_diff','data_motor_5_position_diff', \n",
    "       'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage',\n",
    "       'data_motor_6_temperature_diff', 'data_motor_6_voltage_diff', 'data_motor_6_position_diff']\n",
    "\n",
    "\n",
    "selected_features= ['time','data_motor_1_position',  'data_motor_1_temperature', \n",
    "                    'data_motor_2_position',  \n",
    "                    'data_motor_3_position',  \n",
    "                    'data_motor_4_position', 'data_motor_4_temperature',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', \n",
    "                    'data_motor_1_position_diff', 'data_motor_1_temperature_diff', \n",
    "                    'data_motor_2_position_diff',  \n",
    "                    'data_motor_3_position_diff',  \n",
    "                    'data_motor_4_position_diff', 'data_motor_4_temperature_diff', \n",
    "                    'data_motor_5_position_diff', 'data_motor_5_temperature_diff', \n",
    "                    'data_motor_6_position_diff', 'data_motor_6_temperature_diff',\n",
    "                    'data_motor_1_voltage','data_motor_2_voltage','data_motor_3_voltage','data_motor_5_voltage',\n",
    "                    'data_motor_1_voltage_diff','data_motor_2_voltage_diff','data_motor_3_voltage_diff','data_motor_5_voltage_diff','data_motor_6_voltage_diff']\n",
    "\n",
    "threshold = 1\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "\n",
    "all_model_results = run_all_models(df_data=df_data_smoothing, models=models, feature_list=feature_list_all, \n",
    "                                   threshold=threshold, window_size=window_size, sample_step=sample_step, \n",
    "                                   single_run_result=False)\n",
    "\n",
    "all_model_results = run_all_models(df_data=df_data_smoothing, models=models, feature_list=selected_features, \n",
    "                                   threshold=threshold, window_size=window_size, sample_step=sample_step, \n",
    "                                   single_run_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = {\n",
    "    'Model': [],\n",
    "    'Max error': [],\n",
    "    'RMSE': [],\n",
    "    'Exceed boundary rate': []\n",
    "}\n",
    "\n",
    "for model_name, df_results in all_model_results:\n",
    "    max_error = df_results['Max error'].mean()\n",
    "    mse = df_results['RMSE'].mean()\n",
    "    exceed_boundary_rate = df_results['Exceed boundary rate'].mean()\n",
    "    \n",
    "    summary_data['Model'].append(model_name)\n",
    "    summary_data['Max error'].append(f'{max_error:.2f}')\n",
    "    summary_data['RMSE'].append(f'{mse:.2f}')\n",
    "    summary_data['Exceed boundary rate'].append(f'{exceed_boundary_rate:.2f}')\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"Summary of the results - Only using features from the current moment\\n\")\n",
    "print(summary_df)\n",
    "\n",
    "best_model = summary_df.loc[summary_df['RMSE'].idxmin()]\n",
    "print(f\"\\nThe best model is {best_model['Model']} with a Mean Squared Error (RMSE) of {best_model['RMSE']}.\")\n",
    "print(f\"It uses the features: {', '.join(feature_list_all)} and includes standard scaling as preprocessing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the results - Only using features from the current moment**\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models. Please write a few texts to explain what is the best model you got (including the features and preprocessing you did), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Max error | MRSE | Exceed boundary rate |\n",
    "|---------|----------|-----------|--------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-task 2: Include the features in the past\n",
    "\n",
    "Now, let's consider using the sliding window approach to include the past in the regression model as well. Please have a look at the demo notebook, run your experiment, and report the best models you could have if you apply the sliding window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the results - Sliding window**\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models. Please write a few texts to explain what is the best model you got (including the features and preprocessing you did), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   (also report parameters like window_size, sample_step, prediction_lead_time, etc.) | Max error | MRSE | Exceed boundary rate |\n",
    "|---------|----------|-----------|--------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | \n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Fault detection based on regression model\n",
    "\n",
    "In this exercise, we use the dataset that contains the failure of motor 6 to test the fault detection model based on the regression model trained before. \n",
    "\n",
    "[This notebook](demo_FaultDetectReg.ipynb) presents a demonstration of how to use the provided supporting function to develop fault detection model based on the regression model. Please have a look at this notebook, and try to improve the performance of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the results\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models (including the unsupervised learning models). Please write a few texts to explain what is the best model you got (including key parameters like threshold, window_size, sample_step, prediction_lead_time, etc), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Accuracy | Precision | Recall | F1   |\n",
    "|---------|----------|-----------|--------|------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
