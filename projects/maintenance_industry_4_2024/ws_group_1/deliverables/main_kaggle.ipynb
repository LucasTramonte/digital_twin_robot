{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer,accuracy_score ,precision_score, recall_score\n",
    "from sklearn.metrics import f1_score,confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "from utility import read_all_test_data_from_path\n",
    "from utility import run_cv_one_motor\n",
    "from utility import extract_selected_feature, prepare_sliding_window, FaultDetectReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data.\n",
    "\n",
    "As we shown in WP_1, we can use the `read_all_tst_data_from_path` function to read and visualize data. Please note you have the option to define the preprocessing you would like to do on the original data. For this, you just need to define your preprocessing function and pass its function handle to the `read_all_tst_data_from_path` function.\n",
    "\n",
    "Below is a sample code that reads and visualize all the training dataset, where we apply a simple outlier removal based on validity range as pre-processing. We also remove sequence-to-sequence variablity in the pre-processing. Please note that you need to download the datasets `training_data.zip` and `testing_data.zip` from [kaggle](https://www.kaggle.com/competitions/robot-predictive-maintenance/data) and unzip them. You need to change the path in the sample code below to the path of your datasets.\n",
    "\n",
    "### Training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_path = '../'\n",
    "sys.path.insert(1, utility_path)\n",
    "\n",
    "# Subfunction for data preprocessing.\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    '''\n",
    "    \n",
    "    def remove_outliers(df: pd.DataFrame):\n",
    "        ''' # Description\n",
    "        Remove outliers from the dataframe based on defined valid ranges. \n",
    "        Define a valid range of temperature and voltage. \n",
    "        Use ffil function to replace the invalid measurement with the previous value.\n",
    "        '''\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "        df['temperature'] = df['temperature'].ffill()        \n",
    "\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] <= 9000, np.nan)\n",
    "        df['voltage'] = df['voltage'].ffill()        \n",
    "\n",
    "        df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "        df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "        df['position'] = df['position'].ffill()\n",
    "\n",
    "\n",
    "    def remove_seq_variability(df: pd.DataFrame):\n",
    "        ''' # Description\n",
    "        Remove the sequence-to-sequence variability.\n",
    "        '''\n",
    "        # Tranform the features relative to the first data point.\n",
    "        df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "        df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "        df['position'] = df['position'] - df['position'].iloc[0]\n",
    "        \n",
    "    # Start processing.\n",
    "    remove_outliers(df)\n",
    "    remove_seq_variability(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read all the dataset. Change to your dictionary if needed.\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "df_train = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the dataset. Change to your dictionary if needed.\n",
    "base_dictionary = '../../dataset/testing_data/'\n",
    "df_test = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a classification-based fault detection model.\n",
    "\n",
    "In this section, we use motor $6$ as an example to demonstrate how to train a classification-based fault detection model and apply it to predict the labels on the testing dataset. The basic steps are the same as Workpackage 2. However, you need to pay attention if you use sliding windows to augument the feature space. In this case, the first window_size points in each sequence were scaped in the augumented feature space, as we do not have enough points in the history. In the data challenge, these scaped points need to be predicted manually, as the evaluation is done on all the points, including the scaped points.\n",
    "\n",
    "In the current version of `prepare_sliding_window`, we addressed this issue by filling the missed history based on the closest available observations in the dataset. Therefore, you just need to make sure you use this version of `utility.py`, the scaped points will be filled automatically.\n",
    "\n",
    "Below, you can find a demo how to train a logistic regression model to predict the labels for motor 6. For more details on the classification-bsaed fault detection models, you can have a look at the tutorials in [WP2](../../supporting_scripts/WP_2_20240516/demo_motor_6_lr.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the motor index.\n",
    "motor_idx = 6\n",
    "\n",
    "# Specify the test conditions you would like to include in the training.\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(['20240425_093699', '20240425_094425', '20240426_140055',\n",
    "                                                       '20240503_164675', '20240503_165189',\n",
    "                                                       '20240503_163963', '20240325_155003'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features.\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature',\n",
    "                    'data_motor_4_temperature',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "# Extract the features.\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_all, motor_idx, mdl_type='clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data based on the defined sliding window.\n",
    "window_size = 50\n",
    "sample_step = 10\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    #('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('minimizer', MinMaxScaler()),  # Step 1: MinMaxScaler\n",
    "    ('mdl', LogisticRegression(class_weight='balanced'))    # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'mdl__C': [0.001, 0.01, 0.1, 1, 10, 100]  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1', cv=5)\n",
    "\n",
    "# Train the model.\n",
    "mdl = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for the testing dataset.\n",
    "# Define the features.\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature',\n",
    "                    'data_motor_4_temperature',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "# Add test_condition for extracting different sequences.\n",
    "feature_list_all.append('test_condition')\n",
    "# Get the features.\n",
    "df_test_x = df_test[feature_list_all]\n",
    "# Augument the features in the same way as the training data.\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "# Make prediction.\n",
    "y_pred_6 = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a regression-based fault detection model.\n",
    "\n",
    "In this section, we will apply a regression-based fault detection model to the data. We choose the motor $5$ as an example. For details on regression-based fault detection, please refer to the tutorials in [WP3](../../supporting_scripts/WP_3_20240521/demo_FaultDetectReg.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-train the model.\n",
    "# Get all the normal data for motor 5.\n",
    "normal_test_id = ['20240105_164214',\n",
    "    '20240105_165300',\n",
    "    '20240105_165972',\n",
    "    '20240320_152031',\n",
    "    '20240320_153841',\n",
    "    '20240320_155664',\n",
    "    '20240321_122650',\n",
    "    '20240325_135213',\n",
    "    '20240325_152902',\n",
    "    '20240426_141190',\n",
    "    '20240426_141532',\n",
    "    '20240426_141602',\n",
    "    '20240426_141726',\n",
    "    '20240426_141938',\n",
    "    '20240426_141980',\n",
    "    '20240503_163963',\n",
    "    '20240503_164435',\n",
    "    '20240503_164675',\n",
    "    '20240503_165189'\n",
    "]\n",
    "\n",
    "df_tr_motor_5 = df_train[df_train['test_condition'].isin(normal_test_id)]\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "# Prepare feature and response of the training dataset.\n",
    "x_tr_org, y_temp_tr_org = extract_selected_feature(df_data=df_tr_motor_5, feature_list=feature_list_all, motor_idx=5, mdl_type='reg')\n",
    "\n",
    "# Enrich the features based on the sliding window.\n",
    "window_size = 10\n",
    "sample_step = 1\n",
    "prediction_lead_time = 1 \n",
    "threshold = .9\n",
    "abnormal_limit = 3\n",
    "\n",
    "x_tr, y_temp_tr = prepare_sliding_window(df_x=x_tr_org, y=y_temp_tr_org, window_size=window_size, sample_step=sample_step, prediction_lead_time=prediction_lead_time, mdl_type='reg')\n",
    "\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('regressor', LinearRegression())    # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "mdl_linear_regreession = Pipeline(steps)\n",
    "# Fit the model\n",
    "mdl = mdl_linear_regreession.fit(x_tr, y_temp_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:30<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the fault detector.\n",
    "detector_reg = FaultDetectReg(reg_mdl=mdl, threshold=threshold, abnormal_limit=abnormal_limit, window_size=window_size, sample_step=sample_step, pred_lead_time=prediction_lead_time)\n",
    "\n",
    "# Define the features.\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "# Prepare the testing data.\n",
    "x_test_org, y_temp_test_org = extract_selected_feature(df_data=df_test, feature_list=feature_list_all, motor_idx=5, mdl_type='reg')\n",
    "\n",
    "# Make predicition.\n",
    "y_pred_5, y_response_test_pred = detector_reg.predict(df_x_test=x_test_org, y_response_test=y_temp_test_org, complement_truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the results as a submission file for the data challenge.\n",
    "\n",
    "In this section, we demo how to prepare the results as a submission file for the data challenge. First, we need to download the submission template `sample_submission.csv` from [kaggle](https://www.kaggle.com/competitions/robot-predictive-maintenance/data). As shown below, in this csv files, we just need to give our prediction on the six motors in the corresponding columns. You can find a demo below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>data_motor_1_label</th>\n",
       "      <th>data_motor_2_label</th>\n",
       "      <th>data_motor_3_label</th>\n",
       "      <th>data_motor_4_label</th>\n",
       "      <th>data_motor_5_label</th>\n",
       "      <th>data_motor_6_label</th>\n",
       "      <th>test_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20240527_094865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20240527_094865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20240527_094865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20240527_094865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20240527_094865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  data_motor_1_label  data_motor_2_label  data_motor_3_label  \\\n",
       "0    0                  -1                  -1                  -1   \n",
       "1    1                  -1                  -1                  -1   \n",
       "2    2                  -1                  -1                  -1   \n",
       "3    3                  -1                  -1                  -1   \n",
       "4    4                  -1                  -1                  -1   \n",
       "\n",
       "   data_motor_4_label  data_motor_5_label  data_motor_6_label   test_condition  \n",
       "0                  -1                  -1                  -1  20240527_094865  \n",
       "1                  -1                  -1                  -1  20240527_094865  \n",
       "2                  -1                  -1                  -1  20240527_094865  \n",
       "3                  -1                  -1                  -1  20240527_094865  \n",
       "4                  -1                  -1                  -1  20240527_094865  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the template.\n",
    "path = 'kaggle_data_challenge/sample_submission.csv' # Change to your path.\n",
    "df_submission = pd.read_csv(path)\n",
    "\n",
    "# Initial all values with -1.\n",
    "df_submission.loc[:, ['data_motor_1_label', 'data_motor_2_label', 'data_motor_3_label', 'data_motor_4_label', 'data_motor_5_label', 'data_motor_6_label']] = -1\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each column with your prediction.\n",
    "df_submission['data_motor_5_label'] = y_pred_5\n",
    "df_submission['data_motor_6_label'] = y_pred_6\n",
    "\n",
    "# For the other motors, we just fill with 0.\n",
    "df_submission.loc[:, ['data_motor_1_label', 'data_motor_2_label', 'data_motor_3_label', 'data_motor_4_label']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the submission csv.\n",
    "df_submission.to_csv('../ws_prepare_data_challenge/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
